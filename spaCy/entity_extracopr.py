import spacy

# from spacy.lang.uk import Ukrainian

nlp = spacy.load("uk_core_news_lg")
# ruler = nlp.add_pipe("entity_ruler", before="ner")
# ruler = nlp.add_pipe("entity_ruler")
# patterns = [
#     {
#         "label": "RRR",
#         "pattern": [
#             {"LEMMA": "—ñ–≤–∞–Ω–æ"},
#             {"TEXT": "-"},
#             {"LEMMA": "—Ñ—Ä–∞–Ω–∫—ñ–≤—Å—å–∫"},

#             # {"ENT_TYPE": "LOC"},
#             # {"DEP": "amod"},
#             # {"DEP": "nmod"},
#             # {"ENT_TYPE": "LOC"},
#             # {"LEMMA": "–≤–∏—Ä—É—à–∏—Ç–∏"}

#             # {"POS": "PROPN", "OP": "?"},
#             # {"POS": "PROPN"},
#             # {"TEXT": "-"},
#             # {"POS": "PROPN"}
#         ]
#         # "label": "RRR",
#         # "pattern": [
#         #     {"LEMMA": "–æ–±–æ—Ä–æ–Ω–Ω–∏–π"},
#         #     {"LEMMA": "—Å–ø–æ—Ä—É–¥–∞"}
#         # ]
#     },
#     {
#         "label": "PER",
#         "pattern": [
#             {"DEP": "flat:title", "OP": "?"},
#             {"DEP": "flat:name"},
#             {"TEXT": "-"},
#             {"DEP": "flat:name"}
#         ]
#     },
# ]
# patterns = [{"label": "LOC", "pattern": [
#     {"LEMMA": "–æ–±–æ—Ä–æ–Ω–Ω–∏–π"}, {"LEMMA": "—Å–ø–æ—Ä—É–¥–∞"}]}]
# ruler.add_patterns(patterns)
# [{"label": "ORG", "pattern": "Apple"}]
#             {"label": "GPE", "pattern": [{"LOWER": "san"}, {"LOWER": "francisco"}]}]
# ruler.add_patterns(patterns)
doc = nlp('–ì—Ä—É–ø–∞ —Ç–∞–∫–∏—Ö-—Å–æ–±—ñ –∫–æ–º—É–Ω–∞–ª—å–Ω–∏–∫—ñ–≤ –∑ –Ü–≤–∞–Ω–æ-–§—Ä–∞–Ω–∫—ñ–≤—Å—å–∫–∞ –≤–∏—Ä—É—à–∏–ª–∞ –Ω–∞ –î–æ–Ω–µ—á—á–∏–Ω—É –¥–ª—è –±—É–¥—ñ–≤–Ω–∏—Ü—Ç–≤–∞ –æ–±–æ—Ä–æ–Ω–Ω–∏—Ö —Å–ø–æ—Ä—É–¥. –ü—Ä–æ —Å–ø—ñ–≤—Ä–æ–±—ñ—Ç–Ω–∏–∫—ñ–≤ –ø—ñ–¥–ø—Ä–∏—î–º—Å—Ç–≤–∞ –í–æ–¥–æ–∫–∞–Ω–∞–ª-–°–µ—Ä–≤—ñ—Å —Ä–æ–∑–ø–∏—Ç–∞—î–º–æ –≤ –Ω–∞—à–∏—Ö –∫–æ—Ä–µ—Å–ø–æ–Ω–¥–µ–Ω—Ç—ñ–≤ –ñ–∞–Ω–Ω–∏ –î—É—Ç—á–∞–∫-–ú–∞–ª–∏–Ω–æ–≤—Å—å–∫–æ—ó —Ç–∞ –°—Ç–µ–ø–∞–Ω–∞ –ë–æ–±—Ä–æ–≤–∞.')

for token in doc:
    print('üî∑', token.text, token.lemma_, token.pos_, token.dep_, token.shape_, token.is_stop,
          f'ent_type={token.ent_type_}' if token.ent_type_ else '', token.is_upper, token.is_title)
print("--------------------------------------------------")

# for ent in doc.ents:
#     print(ent.text, ent.lemma_, ent.start_char, ent.end_char, ent.label_)
# print("--------------------------------------------------")
merged_entities = []
current_entity = None

for ent in doc.ents:
    if current_entity is None:
        current_entity = ent
    else:
        # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –Ω–∞ –æ–¥–Ω–∞–∫–æ–≤–∏–π label —ñ —á–∏ –º–æ–∂–Ω–∞ –æ–±'—î–¥–Ω–∞—Ç–∏ (—Ä—ñ–∑–Ω–∏—Ü—è 0 –∞–±–æ 1)
        if current_entity.label_ == ent.label_ and (ent.start_char - current_entity.end_char) <= 1:
            # –û–Ω–æ–≤–ª—é—î–º–æ —Ç–µ–∫—Å—Ç, end_char –¥–ª—è –æ–±'—î–¥–Ω–∞–Ω–æ—ó —Å—É—Ç–Ω–æ—Å—Ç—ñ
            current_entity = spacy.tokens.Span(
                doc, current_entity.start, ent.end, label=current_entity.label_)
        else:
            # –î–æ–¥–∞—î–º–æ –ø–æ—Ç–æ—á–Ω—É —Å—É—Ç–Ω—ñ—Å—Ç—å —É —Å–ø–∏—Å–æ–∫
            merged_entities.append(current_entity)
            current_entity = ent

# –ù–µ –∑–∞–±—É–¥—å—Ç–µ –¥–æ–¥–∞—Ç–∏ –æ—Å—Ç–∞–Ω–Ω—é —Å—É—Ç–Ω—ñ—Å—Ç—å –ø—ñ—Å–ª—è —Ü–∏–∫–ª—É
if current_entity:
    merged_entities.append(current_entity)

# –í–∏–≤–æ–¥–∏–º–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç
for ent in merged_entities:
    print(ent.text, ent.lemma_, ent.start_char, ent.end_char, ent.label_)
