from sentence_transformers import SentenceTransformer
from pprint import pprint
import hdbscan
from collections import Counter
from data import _texts

def main():

    texts = [text[:1000] for text in _texts]

    model = SentenceTransformer(
        # "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
        # "sentence-transformers/all-MiniLM-L6-v2"
        "google/embeddinggemma-300m"
        # "Qwen/Qwen3-Embedding-0.6B"
        # "Qwen/Qwen3-Embedding-8B"
    )

    print("‚ÑπÔ∏è Calculating embeddings...")
    embeddings = model.encode(
        texts,
        batch_size=32,
        show_progress_bar=True,
        normalize_embeddings=True  # –í–ê–ñ–õ–ò–í–û –¥–ª—è HDBSCAN
    )
    
    # for e in embeddings:
    #     pprint(e)

    print("‚ÑπÔ∏è Clustering...")
    clusterer = hdbscan.HDBSCAN(
        # –ü—Ä–∏ –Ω–∏–∑—å–∫—ñ–π –∫—ñ–ª—å–∫–æ—Å—Ç—ñ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω—å
        # min_cluster_size=3,      # –º—ñ–Ω. —Ä–æ–∑–º—ñ—Ä –∫–ª–∞—Å—Ç–µ—Ä–∞
        # min_samples=2,           # —á—É—Ç–ª–∏–≤—ñ—Å—Ç—å –¥–æ —à—É–º—É

        # –†–æ–±–æ—á–∏–π –≤–∞—Ä—ñ–∞–Ω—Ç
        min_cluster_size=7,      # –º—ñ–Ω. —Ä–æ–∑–º—ñ—Ä –∫–ª–∞—Å—Ç–µ—Ä–∞
        min_samples=3,           # —á—É—Ç–ª–∏–≤—ñ—Å—Ç—å –¥–æ —à—É–º—É

        # –ó–∞–ø—Ä–æ–ø–æ–Ω–æ–≤–∞–Ω–æ GPT
        # min_cluster_size=5,      # –º—ñ–Ω. —Ä–æ–∑–º—ñ—Ä –∫–ª–∞—Å—Ç–µ—Ä–∞
        # min_samples=3,           # —á—É—Ç–ª–∏–≤—ñ—Å—Ç—å –¥–æ —à—É–º—É

        metric="euclidean",      # –∑ –Ω–æ—Ä–º–∞–ª—ñ–∑–æ–≤–∞–Ω–∏–º–∏ –≤–µ–∫—Ç–æ—Ä–∞–º–∏ = cosine
        cluster_selection_method="eom"
    )

    labels = clusterer.fit_predict(embeddings)

    # –≥—Ä—É–ø—É—î–º–æ —Ç–µ–∫—Å—Ç–∏ –ø–æ –∫–ª–∞—Å—Ç–µ—Ä–∞—Ö üì¶
    clusters = {}
    for text, label in zip(texts, labels):
        clusters.setdefault(label, []).append(text)

    # —Å–æ—Ä—Ç—É—î–º–æ –∫–ª–∞—Å—Ç–µ—Ä–∏ –∑–∞ –∫—ñ–ª—å–∫—ñ—Å—Ç—é —Ç–µ–∫—Å—Ç—ñ–≤ (—Å–ø–∞–¥–∞–Ω–Ω—è ‚¨áÔ∏è)
    sorted_clusters = sorted(
        clusters.items(),
        key=lambda item: len(item[1]),
        reverse=True
    )

    # –≤–∏–≤–æ–¥–∏–º–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç üñ®Ô∏è
    labels_count = len(sorted_clusters)
    for index, (label, items) in enumerate(sorted_clusters, 1):
        # if label == -1:
        #         continue
        print(f"\nüì¶ CLUSTER {index} of {labels_count} (label: {label}) ({len(items)} messages)")
        pprint([f"üîµ {item[:200]}" for item in items[:(10 if label != -1 else 20)]])
        # for item in items[:(10 if label != -1 else 20)]:
        #     print(f"üîµ {item[:200]}")

    pprint(Counter(labels))


if __name__ == "__main__":
    main()
