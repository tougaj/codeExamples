from sentence_transformers import SentenceTransformer
from pprint import pprint
import hdbscan
from collections import Counter
from data import _texts

def main():

    texts = [text[:1000] for text in _texts]

    model = SentenceTransformer(
        # "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
        # "sentence-transformers/all-MiniLM-L6-v2"
        "google/embeddinggemma-300m"
        # "Qwen/Qwen3-Embedding-0.6B"
        # "Qwen/Qwen3-Embedding-8B"
    )

    print("‚ÑπÔ∏è Calculating embeddings...")
    embeddings = model.encode(
        texts,
        batch_size=32,
        show_progress_bar=True,
        normalize_embeddings=True  # –í–ê–ñ–õ–ò–í–û –¥–ª—è HDBSCAN
    )
    
    # for e in embeddings:
    #     pprint(e)

    print("‚ÑπÔ∏è Clustering...")
    clusterer = hdbscan.HDBSCAN(
        min_cluster_size=3,      # –º—ñ–Ω. —Ä–æ–∑–º—ñ—Ä –∫–ª–∞—Å—Ç–µ—Ä–∞
        min_samples=2,           # —á—É—Ç–ª–∏–≤—ñ—Å—Ç—å –¥–æ —à—É–º—É

        # min_cluster_size=7,      # –º—ñ–Ω. —Ä–æ–∑–º—ñ—Ä –∫–ª–∞—Å—Ç–µ—Ä–∞
        # min_samples=3,           # —á—É—Ç–ª–∏–≤—ñ—Å—Ç—å –¥–æ —à—É–º—É

        # min_cluster_size=5,      # –º—ñ–Ω. —Ä–æ–∑–º—ñ—Ä –∫–ª–∞—Å—Ç–µ—Ä–∞
        # min_samples=3,           # —á—É—Ç–ª–∏–≤—ñ—Å—Ç—å –¥–æ —à—É–º—É
        metric="euclidean",      # –∑ –Ω–æ—Ä–º–∞–ª—ñ–∑–æ–≤–∞–Ω–∏–º–∏ –≤–µ–∫—Ç–æ—Ä–∞–º–∏ = cosine
        cluster_selection_method="eom"
    )

    labels = clusterer.fit_predict(embeddings)

    # –≥—Ä—É–ø—É—î–º–æ —Ç–µ–∫—Å—Ç–∏ –ø–æ –∫–ª–∞—Å—Ç–µ—Ä–∞—Ö üì¶
    clusters = {}
    for text, label in zip(texts, labels):
        clusters.setdefault(label, []).append(text)

    # —Å–æ—Ä—Ç—É—î–º–æ –∫–ª–∞—Å—Ç–µ—Ä–∏ –∑–∞ –∫—ñ–ª—å–∫—ñ—Å—Ç—é —Ç–µ–∫—Å—Ç—ñ–≤ (—Å–ø–∞–¥–∞–Ω–Ω—è ‚¨áÔ∏è)
    sorted_clusters = sorted(
        clusters.items(),
        key=lambda item: len(item[1]),
        reverse=True
    )

    # –≤–∏–≤–æ–¥–∏–º–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç üñ®Ô∏è
    for index, (label, items) in enumerate(sorted_clusters, 1):
        if label == -1:
                continue
        print(f"\nCLUSTER {index} (label {label}) ({len(items)})")
        pprint([item[:200] for item in items[:10]])
        # print(f"\nCLUSTER {label} ({len(items)})")
        # print(items[0][:300])

    # clusters = {}
    # for text, label in zip(texts, labels):
    #     clusters.setdefault(label, []).append(text)

    # for label, items in clusters.items():
    #     if label == -1:
    #         continue
    #     print(f"\nCLUSTER {label} ({len(items)})")
    #     pprint([item[:200] for item in items])
    #     # print(items[0][:300])

    pprint(Counter(labels))


if __name__ == "__main__":
    main()
