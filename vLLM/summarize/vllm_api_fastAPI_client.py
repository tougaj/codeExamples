"""
üåê –ö–ª—ñ—î–Ω—Ç –¥–ª—è —Ä–æ–±–æ—Ç–∏ –∑ vLLM OpenAI-compatible API
–í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î –æ—Ñ—ñ—Ü—ñ–π–Ω—É openai –±—ñ–±–ª—ñ–æ—Ç–µ–∫—É –¥–ª—è summarization
"""

import time
from dataclasses import dataclass
from pprint import pprint
from typing import Dict, List, Optional

import requests

from common import news_headlines, texts

PORT = 8000
SERVER_ADDRESS = f"http://localhost:{PORT}"


@dataclass
class SummarizationConfig:
    """–ö–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—è –¥–ª—è —Ä—ñ–∑–Ω–∏—Ö —Ç–∏–ø—ñ–≤ summarization"""
    temperature: float
    top_p: float
    max_tokens: int
    presence_penalty: float
    frequency_penalty: float
    stop: Optional[List[str]] = None


# üéØ –ì–æ—Ç–æ–≤—ñ –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó
# CONFIGS = {
#     "precise": SummarizationConfig(
#         temperature=0.2,
#         top_p=0.85,
#         max_tokens=200,
#         presence_penalty=0.6,
#         frequency_penalty=0.4,
#         # stop=["</summary>", "\n\n\n", "–¢–µ–∫—Å—Ç:"]
#     ),
#     "balanced": SummarizationConfig(
#         temperature=0.5,
#         top_p=0.9,
#         max_tokens=4196,
#         presence_penalty=0.5,
#         frequency_penalty=0.3,
#         # stop=["</summary>", "\n\n\n"]
#     ),
#     "creative": SummarizationConfig(
#         temperature=0.8,
#         top_p=0.95,
#         max_tokens=600,
#         presence_penalty=0.3,
#         frequency_penalty=0.2,
#         # stop=["</summary>", "\n\n\n"]
#     ),
# }


def check_health() -> bool:
    """
    –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—ñ —Å–µ—Ä–≤–µ—Ä–∞
    """
    try:
        response = requests.get(f"{SERVER_ADDRESS}/health")
        print(f"‚úÖ –°–µ—Ä–≤–µ—Ä –¥–æ—Å—Ç—É–ø–Ω–∏–π. –ü–∞—Ä–∞–º–µ—Ç—Ä–∏:")
        pprint(response.json())
        return True
    except Exception as e:
        print(f"‚ùå –°–µ—Ä–≤–µ—Ä –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∏–π: {e}")
        return False


def print_results(texts: list[str], results: requests.Response, route: str):
    if results.status_code == 200:
        data = results.json()
        for i, (result, text) in enumerate(zip(data['results'], texts), 1):
            print(f"üìÑ –¢–µ–∫—Å—Ç #{i}: {text[:50]}")
            print(f"‚ú® {route}: {result['text']}")
            print(f"‚ú≥Ô∏è –ü—Ä–∏—á–∏–Ω–∞ –∑—É–ø–∏–Ω–∫–∏: {result['finish_reason']}\n")
    else:
        print(f"–ü–æ–º–∏–ª–∫–∞: {results.status_code}, {results.text}")


def process(texts: list[str], route: str):
    print(f"{route}\n{'-'*30}")
    start_time = time.time()
    results = requests.post(f"{SERVER_ADDRESS}/{route}", json={
        "texts": texts,
        # "sampling_params": {
        #     "temperature": 0.7,
        #     "top_p": 0.9,
        #     "max_tokens": 8192
        # }
    })
    end_time = time.time()
    print_results(texts, results, route)
    print(f"‚è±Ô∏è –í—ñ–¥–ø–æ–≤—ñ–¥—å –∑–∞–π–Ω—è–ª–∞ {end_time - start_time:.4f} —Å–µ–∫—É–Ω–¥\n")


# üìä –ü—Ä–∏–∫–ª–∞–¥–∏ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è
if __name__ == "__main__":
    # üè• –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤'—è —Å–µ—Ä–≤–µ—Ä–∞
    print("="*30)
    print("üè• –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –ø—ñ–¥–∫–ª—é—á–µ–Ω–Ω—è –¥–æ —Å–µ—Ä–≤–µ—Ä–∞")
    print("="*30 + "\n")

    if not check_health():
        print("\n‚ö†Ô∏è  –ü–µ—Ä–µ–∫–æ–Ω–∞–π—Å—è, —â–æ vLLM —Å–µ—Ä–≤–µ—Ä –∑–∞–ø—É—â–µ–Ω–∏–π!")
        print("–ó–∞–ø—É—Å—Ç–∏: uv run fastAPI/main.py")
        exit(1)

    # Batch-–æ–±—Ä–æ–±–∫–∞
    print("="*30)
    print("üì¶ –¢–µ—Å—Ç batch-–æ–±—Ä–æ–±–∫–∏")
    print("="*30 + "\n")

    # batch_texts = news_headlines
    batch_texts = texts

    iteration_count = 1
    for i in range(iteration_count):
        print(f"ü´ß Iteration {i+1}/{iteration_count}\n{'*'*30}")
        process(batch_texts, 'translate')
        process(batch_texts, 'summarize')
