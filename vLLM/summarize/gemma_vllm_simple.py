"""
–í–∞—Ä—ñ–∞–Ω—Ç A: –í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è –≤–±—É–¥–æ–≤–∞–Ω–æ–≥–æ —Ç–æ–∫–µ–Ω–∞–π–∑–µ—Ä–∞ vLLM
–ü—Ä–æ—Å—Ç—ñ—à–∏–π –ø—ñ–¥—Ö—ñ–¥, —Ä–µ–∫–æ–º–µ–Ω–¥—É—î—Ç—å—Å—è –¥–ª—è –±—ñ–ª—å—à–æ—Å—Ç—ñ –≤–∏–ø–∞–¥–∫—ñ–≤
"""

# import json
import time
from typing import List

from transformers import AutoTokenizer
from vllm import LLM, SamplingParams

from common import news_headlines, texts

# MODEL_NAME = "google/gemma-2-2b-it"
MODEL_NAME = "google/gemma-3-4b-it"
# MODEL_NAME = "google/gemma-3-12b-it"
# MODEL_NAME = "mistralai/Mistral-7B-Instruct-v0.1"

# üîß –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è –º–æ–¥–µ–ª—ñ
llm = LLM(
    model=MODEL_NAME,  # –∞–±–æ —à–ª—è—Ö –¥–æ –ª–æ–∫–∞–ª—å–Ω–æ—ó –º–æ–¥–µ–ª—ñ
    # trust_remote_code=True,
    max_model_len=8192,  # –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞ –¥–æ–≤–∂–∏–Ω–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É for 4b
    # max_model_len=900,  # –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞ –¥–æ–≤–∂–∏–Ω–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É for 12b
    gpu_memory_utilization=0.5,  # –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è GPU –ø–∞–º'—è—Ç—ñ
    tensor_parallel_size=1,  # –¥–ª—è –º—É–ª—å—Ç–∏-GPU –∑–±—ñ–ª—å—à —Ü–µ –∑–Ω–∞—á–µ–Ω–Ω—è
    # dtype="bfloat16"
    max_num_seqs=15,  # –º–∞–∫—Å–∏–º—É–º –ø–∞—Ä–∞–ª–µ–ª—å–Ω–∏—Ö –∑–∞–ø–∏—Ç—ñ–≤ (10 + –∑–∞–ø–∞—Å)
    swap_space=8,  # GB swap –Ω–∞ CPU (—è–∫—â–æ –Ω–µ –≤–∏—Å—Ç–∞—á–∏—Ç—å VRAM)
    enable_prefix_caching=True,  # –∫–µ—à—É—î —Å–∏—Å—Ç–µ–º–Ω–∏–π –ø—Ä–æ–º–ø—Ç
    enable_chunked_prefill=True,  # –µ—Ñ–µ–∫—Ç–∏–≤–Ω–∞ –æ–±—Ä–æ–±–∫–∞ –¥–æ–≤–≥–∏—Ö –ø—Ä–æ–º–ø—Ç—ñ–≤
    # max_num_batched_tokens_prefill=8192,  # —Ä–æ–∑–º—ñ—Ä —á–∞–Ω–∫—ñ–≤ –¥–ª—è prefill
    dtype="auto",  # –∞–≤—Ç–æ–≤–∏–∑–Ω–∞—á–µ–Ω–Ω—è (float16/bfloat16)
)
# –î–æ–∑–≤–æ–ª—è—î –ø–æ–±–∞—á–∏—Ç–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏ –º–æ–¥–µ–ª—ñ, –∑–æ–∫—Ä–µ–º–∞ –∫–≤–∞–Ω—Ç–∏–∑–∞—Ü—ñ—é
# print(json.dumps(llm.llm_engine.model_config.__dict__, indent=2, default=str))

# üìù –û—Ç—Ä–∏–º–∞–Ω–Ω—è —Ç–æ–∫–µ–Ω–∞–π–∑–µ—Ä–∞ –∑ vLLM
# tokenizer = llm.get_tokenizer()
tokenizer = AutoTokenizer.from_pretrained(
    MODEL_NAME,
    trust_remote_code=True,
)

# ‚öôÔ∏è –ü–∞—Ä–∞–º–µ—Ç—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó –¥–ª—è summarization
sampling_params = SamplingParams(
    temperature=0.5,  # –Ω–∏–∑—å–∫–∞ –¥–ª—è –±—ñ–ª—å—à –¥–µ—Ç–µ—Ä–º—ñ–Ω–æ–≤–∞–Ω–∏—Ö —Ä–µ–∑—é–º–µ
    # temperature=0.1,  # –Ω–∏–∑—å–∫–∞ –¥–ª—è –±—ñ–ª—å—à —Ç–æ—á–Ω–∏—Ö –ø–µ—Ä–µ–∫–ª–∞–¥—ñ–≤
    top_p=0.9,  # nucleus sampling
    max_tokens=400,  # –º–∞–∫—Å–∏–º—É–º —Ç–æ–∫–µ–Ω—ñ–≤ –¥–ª—è —Ä–µ–∑—é–º–µ
    # max_tokens=8192,  # –º–∞–∫—Å–∏–º—É–º —Ç–æ–∫–µ–Ω—ñ–≤ –¥–ª—è –ø–µ—Ä–µ–∫–ª–∞–¥—É
    presence_penalty=0.5,  # –∑–Ω–∏–∂—É—î –ø–æ–≤—Ç–æ—Ä–µ–Ω–Ω—è –∫–æ–Ω—Ü–µ–ø—Ü—ñ–π
    frequency_penalty=0.3,  # –∑–Ω–∏–∂—É—î –ø–æ–≤—Ç–æ—Ä–µ–Ω–Ω—è —Å–ª—ñ–≤
    # stop=["</summary>", "\n\n\n"],  # —Å—Ç–æ–ø-—Ç–æ–∫–µ–Ω–∏
)


def prepare_chat_prompt(text: str) -> str:
    """
    –ü—ñ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø—Ä–æ–º–ø—Ç—É –∑ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è–º chat template
    """
    # messages = [
    #     {
    #         "role": "user",
    #         "content": f"""–¢–∏ ‚Äî –ø—Ä–æ—Ñ–µ—Å—ñ–π–Ω–∏–π –ø–µ—Ä–µ–∫–ª–∞–¥–∞—á —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—ó –º–æ–≤–∏.
    # –¢–≤–æ—î –∑–∞–≤–¥–∞–Ω–Ω—è ‚Äî –ø–µ—Ä–µ–∫–ª–∞—Å—Ç–∏ –æ—Ç—Ä–∏–º–∞–Ω–∏–π —Ç–µ–∫—Å—Ç —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—é **—Ç–æ—á–Ω–æ –∑–∞ –∑–º—ñ—Å—Ç–æ–º**, –∞–ª–µ **–ø—Ä–∏—Ä–æ–¥–Ω–æ –π –≤–∏—Ä–∞–∑–Ω–æ –∑–∞ —Ñ–æ—Ä–º–æ—é**, –¥–æ—Ç—Ä–∏–º—É—é—á–∏—Å—å —Ç–∞–∫–∏—Ö –ø—Ä–∞–≤–∏–ª:
    # 1. –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π **–≥—Ä–∞–º–∞—Ç–∏—á–Ω–æ –ø—Ä–∞–≤–∏–ª—å–Ω—É, –ø—Ä–∏—Ä–æ–¥–Ω—É —Ç–∞ —Å—Ç–∏–ª—ñ—Å—Ç–∏—á–Ω–æ –¥–æ—Ä–µ—á–Ω—É** —É–∫—Ä–∞—ó–Ω—Å—å–∫—É –º–æ–≤—É.
    # 2. **–ù–µ –ø–µ—Ä–µ–∫–ª–∞–¥–∞–π –¥–æ—Å–ª—ñ–≤–Ω–æ.** –£–Ω–∏–∫–∞–π –∫–∞–ª—å–æ–∫, —à—Ç—É—á–Ω–∏—Ö –∑–≤–æ—Ä–æ—Ç—ñ–≤ —ñ –±—É–∫–≤–∞–ª—å–Ω–∏—Ö –∫–æ–Ω—Å—Ç—Ä—É–∫—Ü—ñ–π ‚Äî –∑–∞–º—ñ–Ω—é–π —ó—Ö –Ω–∞ –ø—Ä–∏—Ä–æ–¥–Ω—ñ —É–∫—Ä–∞—ó–Ω—Å—å–∫—ñ –≤—ñ–¥–ø–æ–≤—ñ–¥–Ω–∏–∫–∏ –∞–±–æ —ñ–¥—ñ–æ–º–∞—Ç–∏—á–Ω—ñ –≤–∏—Ä–∞–∑–∏.
    # 3. –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π —É–∫—Ä–∞—ó–Ω—Å—å–∫—ñ –ª–∞–ø–∫–∏ **¬´...¬ª** –∑–∞–º—ñ—Å—Ç—å —ñ–Ω–æ–∑–µ–º–Ω–∏—Ö –≤–∞—Ä—ñ–∞–Ω—Ç—ñ–≤ (‚Äû...‚Äú, "...", ‚Äò...‚Äô —Ç–æ—â–æ), –¥–æ—Ç—Ä–∏–º—É—é—á–∏—Å—å –ø—Ä–∞–≤–∏–ª –ø—É–Ω–∫—Ç—É–∞—Ü—ñ—ó.
    # 4. –ó–∞ –ø–æ—Ç—Ä–µ–±–∏ –∑–∞—Å—Ç–æ—Å–æ–≤—É–π **—Ñ–æ—Ä–º–∞—Ç—É–≤–∞–Ω–Ω—è Markdown**:
    #    * –∑–∞–≥–æ–ª–æ–≤–∫–∏ (`#`, `##`),
    #    * —Å–ø–∏—Å–∫–∏,
    #    * **–∂–∏—Ä–Ω–∏–π** –∞–±–æ *–∫—É—Ä—Å–∏–≤–Ω–∏–π* —Ç–µ–∫—Å—Ç,
    #    * **–∂–∏—Ä–Ω–∏–π** —Ç–µ–∫—Å—Ç –¥–ª—è —ñ–º–µ–Ω–æ–≤–∞–Ω–∏—Ö —Å—É—Ç–Ω–æ—Å—Ç–µ–π (NER),
    #    * —Ü–∏—Ç–∞—Ç–∏ —Ç–æ—â–æ.
    # 5. –ù–µ –¥–æ–¥–∞–≤–∞–π –ø–æ—è—Å–Ω–µ–Ω—å, –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ–≤, –ø—Ä–∏–º—ñ—Ç–æ–∫ —á–∏ —Å–ª—É–∂–±–æ–≤–∏—Ö —Ñ—Ä–∞–∑.
    # 6. –Ø–∫—â–æ –Ω–∞–¥–∞–Ω–æ —Ç–µ–∫—Å—Ç —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—é, –∞–±–æ —Ä–æ—Å—ñ–π—Å—å–∫–æ—é –º–æ–≤–æ—é, —Ç–æ –ø–µ—Ä–µ–∫–ª–∞–¥–∞—Ç–∏ –π–æ–≥–æ –Ω–µ –ø–æ—Ç—Ä—ñ–±–Ω–æ. –í —Ç–∞–∫–æ–º—É —Ä–∞–∑—ñ –ø—Ä–æ—Å—Ç–æ –≤–∏–≤–µ–¥–∏ –ø—É—Å—Ç–∏–π —Ä—è–¥–æ–∫.
    # 7. **–£ –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ –ø–æ–¥–∞–≤–∞–π –ª–∏—à–µ –ø–µ—Ä–µ–∫–ª–∞–¥–µ–Ω–∏–π —Ç–µ–∫—Å—Ç.**
    # –¢–µ–∫—Å—Ç –¥–ª—è –ø–µ—Ä–µ–∫–ª–∞–¥—É:\n\n{text}""",
    #     }
    # ]
    messages = [
        {
            "role": "user",
            "content": f"""–¢–∏ ‚Äî —Å–∏—Å—Ç–µ–º–∞ —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è —Å—Ç–∏—Å–ª–∏—Ö –Ω–æ–≤–∏–Ω–Ω–∏—Ö —Ä–µ–∑—é–º–µ.
–û—Ç—Ä–∏–º—É—î—à —Ç–µ–∫—Å—Ç —Å—Ç–∞—Ç—Ç—ñ –∑ –Ω–æ–≤–∏–Ω–Ω–æ–≥–æ –¥–∂–µ—Ä–µ–ª–∞ –±—É–¥—å-—è–∫–æ—é –º–æ–≤–æ—é.
–¢–≤–æ—î –∑–∞–≤–¥–∞–Ω–Ω—è ‚Äî –ø—ñ–¥–≥–æ—Ç—É–≤–∞—Ç–∏ –∫–æ—Ä–æ—Ç–∫–µ —Ä–µ–∑—é–º–µ **—É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—é –º–æ–≤–æ—é** (3‚Äì5 —Ä–µ—á–µ–Ω—å), –¥–æ—Ç—Ä–∏–º—É—é—á–∏—Å—å —Ç–∞–∫–∏—Ö –ø—Ä–∞–≤–∏–ª:
1. –†–µ–∑—é–º–µ –º–∞—î **–æ–±–æ–≤'—è–∑–∫–æ–≤–æ** –±—É—Ç–∏ —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—é –º–æ–≤–æ—é!.
2. **–ü–µ—Ä–µ–¥–∞–π –≥–æ–ª–æ–≤–Ω–∏–π –∑–º—ñ—Å—Ç —Ç–æ—á–Ω–æ –π —Å—Ç–∏—Å–ª–æ** ‚Äî –∑–æ—Å–µ—Ä–µ–¥—å—Å—è –Ω–∞ –∫–ª—é—á–æ–≤–∏—Ö —Ñ–∞–∫—Ç–∞—Ö, –ø–æ–¥—ñ—è—Ö —ñ —Ç–µ–∑–∞—Ö.
3. –Ø–∫—â–æ –≤ —Ç–µ–∫—Å—Ç—ñ —î —Ü—ñ –¥–∞–Ω—ñ, **–∑–∞–∑–Ω–∞—á –æ—Å–Ω–æ–≤–Ω–∏—Ö —É—á–∞—Å–Ω–∏–∫—ñ–≤, –º—ñ—Å—Ü–µ, —á–∞—Å —ñ –ø—Ä–∏—á–∏–Ω—É –ø–æ–¥—ñ—ó.**
4. **–£–Ω–∏–∫–∞–π** –¥—Ä—É–≥–æ—Ä—è–¥–Ω–∏—Ö –¥–µ—Ç–∞–ª–µ–π, –ø—Ä–∏–∫–ª–∞–¥—ñ–≤, —Ü–∏—Ç–∞—Ç, –æ—Ü—ñ–Ω–Ω–∏—Ö —Å—É–¥–∂–µ–Ω—å —ñ –µ–º–æ—Ü—ñ–π–Ω–æ–≥–æ —Ç–æ–Ω—É.
5. –î–æ—Ç—Ä–∏–º—É–π—Å—è **–Ω–µ–π—Ç—Ä–∞–ª—å–Ω–æ–≥–æ, –æ–±‚Äô—î–∫—Ç–∏–≤–Ω–æ–≥–æ —Ç–∞ —ñ–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω–æ–≥–æ —Å—Ç–∏–ª—é.**
6. –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π **–ø—Ä–∏—Ä–æ–¥–Ω—É, –∑—Ä–æ–∑—É–º—ñ–ª—É –π –≥—Ä–∞–º–∞—Ç–∏—á–Ω–æ –ø—Ä–∞–≤–∏–ª—å–Ω—É** —É–∫—Ä–∞—ó–Ω—Å—å–∫—É –º–æ–≤—É.
7. –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π Markdown **–∂–∏—Ä–Ω–∏–π** —Ç–µ–∫—Å—Ç –¥–ª—è —ñ–º–µ–Ω–æ–≤–∞–Ω–∏—Ö —Å—É—Ç–Ω–æ—Å—Ç–µ–π (NER).
8. **–£ –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ –ø–æ–¥–∞–π –ª–∏—à–µ —Ä–µ–∑—é–º–µ** ‚Äî –±–µ–∑ –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ–≤, –ø–æ—è—Å–Ω–µ–Ω—å, –∑–∞–≥–æ–ª–æ–≤–∫—ñ–≤ –∞–±–æ —Ñ–æ—Ä–º–∞—Ç—É–≤–∞–Ω–Ω—è.
–¢–µ–∫—Å—Ç –¥–ª—è —Ä–µ–∑—é–º–µ:\n\n{text}""",
        }
    ]
#     messages = [
#         {
#             "role": "user",
#             "content": f"""–°—Ç–≤–æ—Ä–∏ —Å—Ç–∏—Å–ª–µ —Ä–µ–∑—é–º–µ –Ω–∞—Å—Ç—É–ø–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç—É —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—é –º–æ–≤–æ—é.
# –†–µ–∑—é–º–µ –º–∞—î –±—É—Ç–∏ —á—ñ—Ç–∫–∏–º, —ñ–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω–∏–º —Ç–∞ –Ω–µ –ø–µ—Ä–µ–≤–∏—â—É–≤–∞—Ç–∏ 3-4 —Ä–µ—á–µ–Ω–Ω—è.

# –¢–µ–∫—Å—Ç:
# {text}

# –†–µ–∑—é–º–µ:""",
#         }
#     ]

    # üéØ –ó–∞—Å—Ç–æ—Å—É–≤–∞–Ω–Ω—è chat template
    prompt = tokenizer.apply_chat_template(
        messages,
        tokenize=False,  # –ø–æ–≤–µ—Ä—Ç–∞—î–º–æ string, –Ω–µ —Ç–æ–∫–µ–Ω–∏
        add_generation_prompt=True,  # –¥–æ–¥–∞—î prompt –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ
    )
    # print(prompt)

    return prompt


def summarize_texts(texts: List[str]) -> list[tuple[str, str | None]]:
    """
    Batch-–æ–±—Ä–æ–±–∫–∞ —Ç–µ–∫—Å—Ç—ñ–≤ –¥–ª—è —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è —Ä–µ–∑—é–º–µ

    Args:
        texts: –°–ø–∏—Å–æ–∫ —Ç–µ–∫—Å—Ç—ñ–≤ –¥–ª—è summarization

    Returns:
        –°–ø–∏—Å–æ–∫ –∑–≥–µ–Ω–µ—Ä–æ–≤–∞–Ω–∏—Ö —Ä–µ–∑—é–º–µ
    """
    # –ü—ñ–¥–≥–æ—Ç–æ–≤–∫–∞ –≤—Å—ñ—Ö –ø—Ä–æ–º–ø—Ç—ñ–≤
    prompts = [prepare_chat_prompt(text) for text in texts]

    # üöÄ Batch inference
    outputs = llm.generate(prompts, sampling_params)

    # Extraction —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
    summaries = [(output.outputs[0].text.strip(), output.outputs[0].finish_reason) for output in outputs]

    return summaries


def process(texts: list[str]):
    print("üîÑ –ü–æ—á–∞—Ç–æ–∫ –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó —Ä–µ–∑—é–º–µ...\n")

    start_time = time.time()
    summaries = summarize_texts(texts)
    end_time = time.time()

    # –í–∏–≤–µ–¥–µ–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
    for i, (original, summary) in enumerate(zip(texts, summaries), 1):
        (text, reason) = summary
        print(f"üìÑ –¢–µ–∫—Å—Ç #{i}:")
        print(f"{original[:100]}...")
        print(f"\n‚ú® –†–µ–∑—é–º–µ:")
        print(f"{text}")
        print(f"\n‚ú≥Ô∏è –ü—Ä–∏—á–∏–Ω–∞ –∑—É–ø–∏–Ω–∫–∏:")
        print(f"{reason}")
        print("\n" + "=" * 80 + "\n")

    # üìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    print(f"‚úÖ –û–±—Ä–æ–±–ª–µ–Ω–æ —Ç–µ–∫—Å—Ç—ñ–≤: {len(sample_texts)}")
    print(
        f"üìä –°–µ—Ä–µ–¥–Ω—è –¥–æ–≤–∂–∏–Ω–∞ —Ä–µ–∑—é–º–µ: {sum(len(s[0].split()) for s in summaries) / len(summaries):.1f} —Å–ª—ñ–≤"
    )
    print(f"‚è±Ô∏è –í—ñ–¥–ø–æ–≤—ñ–¥—å –∑–∞–π–Ω—è–ª–∞ {end_time - start_time:.4f} —Å–µ–∫—É–Ω–¥")


# üìä –ü—Ä–∏–∫–ª–∞–¥ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è
if __name__ == "__main__":
    # –¢–µ—Å—Ç–æ–≤—ñ —Ç–µ–∫—Å—Ç–∏
    # sample_texts = [
    #     """–®—Ç—É—á–Ω–∏–π —ñ–Ω—Ç–µ–ª–µ–∫—Ç (–®–Ü) ‚Äî —Ü–µ –≥–∞–ª—É–∑—å –∫–æ–º–ø'—é—Ç–µ—Ä–Ω–∏—Ö –Ω–∞—É–∫, —è–∫–∞ –∑–∞–π–º–∞—î—Ç—å—Å—è —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è–º
    #     —ñ–Ω—Ç–µ–ª–µ–∫—Ç—É–∞–ª—å–Ω–∏—Ö –º–∞—à–∏–Ω, –∑–¥–∞—Ç–Ω–∏—Ö –≤–∏–∫–æ–Ω—É–≤–∞—Ç–∏ –∑–∞–≤–¥–∞–Ω–Ω—è, —â–æ –∑–∞–∑–≤–∏—á–∞–π –ø–æ—Ç—Ä–µ–±—É—é—Ç—å –ª—é–¥—Å—å–∫–æ–≥–æ
    #     —ñ–Ω—Ç–µ–ª–µ–∫—Ç—É. –¶–µ –≤–∫–ª—é—á–∞—î —Ç–∞–∫—ñ –∑–¥—ñ–±–Ω–æ—Å—Ç—ñ, —è–∫ —Ä–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è –º–æ–≤–∏, –ø—Ä–∏–π–Ω—è—Ç—Ç—è —Ä—ñ—à–µ–Ω—å,
    #     –ø–µ—Ä–µ–∫–ª–∞–¥ –º–æ–≤ —Ç–∞ –≤—ñ–∑—É–∞–ª—å–Ω–µ —Å–ø—Ä–∏–π–Ω—è—Ç—Ç—è. –°—É—á–∞—Å–Ω–∏–π –®–Ü –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î –º–∞—à–∏–Ω–Ω–µ –Ω–∞–≤—á–∞–Ω–Ω—è
    #     —Ç–∞ –≥–ª–∏–±–æ–∫—ñ –Ω–µ–π—Ä–æ–Ω–Ω—ñ –º–µ—Ä–µ–∂—ñ –¥–ª—è –¥–æ—Å—è–≥–Ω–µ–Ω–Ω—è –≤—Ä–∞–∂–∞—é—á–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ —É —Ä—ñ–∑–Ω–∏—Ö —Å—Ñ–µ—Ä–∞—Ö.""",

    #     """Python —î –æ–¥–Ω—ñ—î—é –∑ –Ω–∞–π–ø–æ–ø—É–ª—è—Ä–Ω—ñ—à–∏—Ö –º–æ–≤ –ø—Ä–æ–≥—Ä–∞–º—É–≤–∞–Ω–Ω—è —É —Å–≤—ñ—Ç—ñ. –í–æ–Ω–∞ –≤—ñ–¥–æ–º–∞ —Å–≤–æ—î—é
    #     –ø—Ä–æ—Å—Ç–æ—Ç–æ—é —Ç–∞ —á–∏—Ç–∞–±–µ–ª—å–Ω—ñ—Å—Ç—é —Å–∏–Ω—Ç–∞–∫—Å–∏—Å—É, —â–æ —Ä–æ–±–∏—Ç—å —ó—ó —ñ–¥–µ–∞–ª—å–Ω–æ—é –¥–ª—è –ø–æ—á–∞—Ç–∫—ñ–≤—Ü—ñ–≤.
    #     Python —à–∏—Ä–æ–∫–æ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è –≤ –≤–µ–±-—Ä–æ–∑—Ä–æ–±—Ü—ñ, –Ω–∞—É–∫–æ–≤–æ–º—É –ø—Ä–æ–≥—Ä–∞–º—É–≤–∞–Ω–Ω—ñ, –∞–Ω–∞–ª—ñ–∑—ñ
    #     –¥–∞–Ω–∏—Ö, —à—Ç—É—á–Ω–æ–º—É —ñ–Ω—Ç–µ–ª–µ–∫—Ç—ñ —Ç–∞ –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü—ñ—ó. –í–µ–ª–∏–∫–∞ –∫—ñ–ª—å–∫—ñ—Å—Ç—å –±—ñ–±–ª—ñ–æ—Ç–µ–∫ —Ç–∞ –∞–∫—Ç–∏–≤–Ω–∞
    #     —Å–ø—ñ–ª—å–Ω–æ—Ç–∞ —Ä–æ–±–ª—è—Ç—å Python —É–Ω—ñ–≤–µ—Ä—Å–∞–ª—å–Ω–∏–º —ñ–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–º –¥–ª—è —Ä–æ–∑—Ä–æ–±–Ω–∏–∫—ñ–≤.""",
    # ]
    sample_texts = texts
    iteration_count = 1
    for i in range(iteration_count):
        print(f"\n\nü´ß Iteration {i+1}/{iteration_count}\n{'*'*50}")
        process(sample_texts)

    # print("üîÑ –ü–æ—á–∞—Ç–æ–∫ –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó —Ä–µ–∑—é–º–µ...\n")

    # start_time = time.time()
    # summaries = summarize_texts(sample_texts)
    # end_time = time.time()

    # # –í–∏–≤–µ–¥–µ–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
    # for i, (original, summary) in enumerate(zip(sample_texts, summaries), 1):
    #     (text, reason) = summary
    #     print(f"üìÑ –¢–µ–∫—Å—Ç #{i}:")
    #     print(f"{original[:100]}...")
    #     print(f"\n‚ú® –†–µ–∑—é–º–µ:")
    #     print(f"{text}")
    #     print(f"\n‚ú≥Ô∏è –ü—Ä–∏—á–∏–Ω–∞ –∑—É–ø–∏–Ω–∫–∏:")
    #     print(f"{reason}")
    #     print("\n" + "=" * 80 + "\n")

    # # üìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    # print(f"‚úÖ –û–±—Ä–æ–±–ª–µ–Ω–æ —Ç–µ–∫—Å—Ç—ñ–≤: {len(sample_texts)}")
    # print(
    #     f"üìä –°–µ—Ä–µ–¥–Ω—è –¥–æ–≤–∂–∏–Ω–∞ —Ä–µ–∑—é–º–µ: {sum(len(s[0].split()) for s in summaries) / len(summaries):.1f} —Å–ª—ñ–≤"
    # )
    # print(f"‚è±Ô∏è –í—ñ–¥–ø–æ–≤—ñ–¥—å –∑–∞–π–Ω—è–ª–∞ {end_time - start_time:.4f} —Å–µ–∫—É–Ω–¥")
