"""
üöÄ –í–∞—Ä—ñ–∞–Ω—Ç B –∑ Speculative Decoding
Target Model: Gemma 2 12B IT
Draft Model: Gemma 2 4B IT (–¥–ª—è –ø—Ä–∏—Å–∫–æ—Ä–µ–Ω–Ω—è)

Speculative decoding –º–æ–∂–µ –ø—Ä–∏—Å–∫–æ—Ä–∏—Ç–∏ –≥–µ–Ω–µ—Ä–∞—Ü—ñ—é –Ω–∞ 1.5-3x –±–µ–∑ –≤—Ç—Ä–∞—Ç–∏ —è–∫–æ—Å—Ç—ñ!
"""

from vllm import LLM, SamplingParams
from transformers import AutoTokenizer
from typing import List, Dict, Optional
import time

# üîß –ö–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—è –º–æ–¥–µ–ª–µ–π
TARGET_MODEL = "google/gemma-2-12b-it"  # –æ—Å–Ω–æ–≤–Ω–∞ –º–æ–¥–µ–ª—å (—Ç–æ—á–Ω–∞)
DRAFT_MODEL = "google/gemma-2-4b-it"     # draft –º–æ–¥–µ–ª—å (—à–≤–∏–¥–∫–∞)

# üìù –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è LLM –∑ speculative decoding
print("üîÑ –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –º–æ–¥–µ–ª–µ–π (—Ü–µ –º–æ–∂–µ –∑–∞–π–Ω—è—Ç–∏ —Ö–≤–∏–ª–∏–Ω—É)...")
print(f"üéØ Target model: {TARGET_MODEL}")
print(f"‚ö° Draft model: {DRAFT_MODEL}")

llm = LLM(
    model=TARGET_MODEL,
    trust_remote_code=True,
    max_model_len=8192,
    gpu_memory_utilization=0.85,  # —Ç—Ä–æ—Ö–∏ –º–µ–Ω—à–µ, –±–æ –¥–≤—ñ –º–æ–¥–µ–ª—ñ
    tensor_parallel_size=1,
    
    # üöÄ SPECULATIVE DECODING –ø–∞—Ä–∞–º–µ—Ç—Ä–∏
    speculative_model=DRAFT_MODEL,  # draft –º–æ–¥–µ–ª—å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó –∫–∞–Ω–¥–∏–¥–∞—Ç—ñ–≤
    num_speculative_tokens=5,  # —Å–∫—ñ–ª—å–∫–∏ —Ç–æ–∫–µ–Ω—ñ–≤ –≥–µ–Ω–µ—Ä—É—î draft –∑–∞ —Ä–∞–∑ (3-5 –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ)
    use_v2_block_manager=True,  # –ø–æ–∫—Ä–∞—â–µ–Ω–∏–π memory manager –¥–ª—è spec decoding
    enable_chunked_prefill=True,  # –¥–ª—è –µ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—ó —Ä–æ–±–æ—Ç–∏ –∑ –¥–æ–≤–≥–∏–º–∏ –ø—Ä–æ–º–ø—Ç–∞–º–∏
)

print("‚úÖ –ú–æ–¥–µ–ª—ñ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ!\n")

# üìù –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —Ç–æ–∫–µ–Ω–∞–π–∑–µ—Ä–∞ (–¥–ª—è target –º–æ–¥–µ–ª—ñ)
tokenizer = AutoTokenizer.from_pretrained(
    TARGET_MODEL,
    trust_remote_code=True,
)

# ‚öôÔ∏è –ö–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—è –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤ –¥–ª—è summarization
# –ù–∞–ª–∞—à—Ç—É–≤–∞–≤ –ø—ñ–¥ speculative decoding
SUMMARIZATION_CONFIGS = {
    "precise": SamplingParams(
        temperature=0.2,
        top_p=0.85,
        max_tokens=150,
        presence_penalty=0.6,
        frequency_penalty=0.4,
        stop=["</summary>", "\n\n\n", "–¢–µ–∫—Å—Ç:"],
        # –î–ª—è spec decoding –º–æ–∂–Ω–∞ –¥–æ–¥–∞—Ç–∏:
        use_beam_search=False,  # beam search –Ω–µ—Å—É–º—ñ—Å–Ω–∏–π –∑—ñ spec decoding
    ),
    "balanced": SamplingParams(
        temperature=0.5,
        top_p=0.9,
        max_tokens=200,
        presence_penalty=0.5,
        frequency_penalty=0.3,
        stop=["</summary>", "\n\n\n"],
    ),
    "creative": SamplingParams(
        temperature=0.8,
        top_p=0.95,
        max_tokens=250,
        presence_penalty=0.3,
        frequency_penalty=0.2,
        stop=["</summary>", "\n\n\n"],
    ),
}


class GemmaSpeculativeSummarizer:
    """
    Summarizer –∑ speculative decoding –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ—ó —à–≤–∏–¥–∫–æ—Å—Ç—ñ
    """
    
    def __init__(self, llm_instance, tokenizer_instance):
        self.llm = llm_instance
        self.tokenizer = tokenizer_instance
        self.total_tokens_generated = 0
        self.total_time = 0.0
    
    def create_chat_messages(self, text: str, custom_instruction: str = None) -> List[Dict]:
        """–°—Ç–≤–æ—Ä–µ–Ω–Ω—è –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω—å –¥–ª—è chat template"""
        default_instruction = """–°—Ç–≤–æ—Ä–∏ —Å—Ç–∏—Å–ª–µ —Ä–µ–∑—é–º–µ –Ω–∞—Å—Ç—É–ø–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç—É —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—é –º–æ–≤–æ—é. 
–†–µ–∑—é–º–µ –º–∞—î –±—É—Ç–∏ —á—ñ—Ç–∫–∏–º, —ñ–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω–∏–º —Ç–∞ –Ω–µ –ø–µ—Ä–µ–≤–∏—â—É–≤–∞—Ç–∏ 3-4 —Ä–µ—á–µ–Ω–Ω—è."""
        
        instruction = custom_instruction or default_instruction
        
        messages = [
            {
                "role": "user",
                "content": f"{instruction}\n\n–¢–µ–∫—Å—Ç:\n{text}\n\n–†–µ–∑—é–º–µ:"
            }
        ]
        
        return messages
    
    def apply_chat_template(self, messages: List[Dict]) -> str:
        """–ó–∞—Å—Ç–æ—Å—É–≤–∞–Ω–Ω—è chat template —á–µ—Ä–µ–∑ HF —Ç–æ–∫–µ–Ω–∞–π–∑–µ—Ä"""
        prompt = self.tokenizer.apply_chat_template(
            messages,
            tokenize=False,
            add_generation_prompt=True,
        )
        return prompt
    
    def summarize_batch(
        self, 
        texts: List[str], 
        config: str = "balanced",
        custom_instruction: str = None,
        show_progress: bool = True,
        show_speedup: bool = True,
    ) -> List[Dict]:
        """
        Batch-–æ–±—Ä–æ–±–∫–∞ –∑ speculative decoding
        
        Args:
            texts: –°–ø–∏—Å–æ–∫ —Ç–µ–∫—Å—Ç—ñ–≤
            config: –ö–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—è ('precise', 'balanced', 'creative')
            custom_instruction: –ö–∞—Å—Ç–æ–º–Ω–∞ —ñ–Ω—Å—Ç—Ä—É–∫—Ü—ñ—è
            show_progress: –ü–æ–∫–∞–∑—É–≤–∞—Ç–∏ –ø—Ä–æ–≥—Ä–µ—Å
            show_speedup: –ü–æ–∫–∞–∑—É–≤–∞—Ç–∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø—Ä–∏—Å–∫–æ—Ä–µ–Ω–Ω—è
        """
        if show_progress:
            print(f"üîÑ –ü—ñ–¥–≥–æ—Ç–æ–≤–∫–∞ {len(texts)} —Ç–µ–∫—Å—Ç—ñ–≤ –¥–ª—è speculative decoding...")
        
        start_time = time.time()
        
        # –ü—ñ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø—Ä–æ–º–ø—Ç—ñ–≤
        prompts = []
        for text in texts:
            messages = self.create_chat_messages(text, custom_instruction)
            prompt = self.apply_chat_template(messages)
            prompts.append(prompt)
        
        # –í–∏–±—ñ—Ä –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤
        sampling_params = SUMMARIZATION_CONFIGS.get(config, SUMMARIZATION_CONFIGS["balanced"])
        
        if show_progress:
            print(f"üöÄ –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è –∑ speculative decoding (config: {config})...")
            print(f"‚ö° Draft model –≥–µ–Ω–µ—Ä—É—î –∫–∞–Ω–¥–∏–¥–∞—Ç–∏, target model –≤–µ—Ä–∏—Ñ—ñ–∫—É—î")
        
        # üéØ –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è –∑—ñ speculative decoding
        outputs = self.llm.generate(prompts, sampling_params)
        
        # –û–±—Ä–æ–±–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
        results = []
        total_tokens = 0
        
        for i, output in enumerate(outputs):
            tokens_generated = len(output.outputs[0].token_ids)
            total_tokens += tokens_generated
            
            result = {
                "original_text": texts[i],
                "summary": output.outputs[0].text.strip(),
                "tokens_generated": tokens_generated,
                "finish_reason": output.outputs[0].finish_reason,
            }
            results.append(result)
        
        elapsed_time = time.time() - start_time
        self.total_tokens_generated += total_tokens
        self.total_time += elapsed_time
        
        if show_progress:
            print(f"‚úÖ –ó–∞–≤–µ—Ä—à–µ–Ω–æ –∑–∞ {elapsed_time:.2f}s")
            print(f"üìä –®–≤–∏–¥–∫—ñ—Å—Ç—å: {len(texts)/elapsed_time:.2f} —Ç–µ–∫—Å—Ç—ñ–≤/—Å")
            print(f"üî¢ –¢–æ–∫–µ–Ω—ñ–≤ –∑–≥–µ–Ω–µ—Ä–æ–≤–∞–Ω–æ: {total_tokens}")
            print(f"‚ö° –®–≤–∏–¥–∫—ñ—Å—Ç—å –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó: {total_tokens/elapsed_time:.1f} —Ç–æ–∫–µ–Ω—ñ–≤/—Å")
        
        if show_speedup:
            # –ü—Ä–∏–±–ª–∏–∑–Ω–∞ –æ—Ü—ñ–Ω–∫–∞ –ø—Ä–∏—Å–∫–æ—Ä–µ–Ω–Ω—è
            # –ë–µ–∑ spec decoding gemma-12b –≥–µ–Ω–µ—Ä—É—î ~20-30 tokens/s
            # –ó spec decoding –æ—á—ñ–∫—É—î–º–æ ~40-60 tokens/s (1.5-2.5x speedup)
            tokens_per_sec = total_tokens / elapsed_time
            estimated_baseline = 25  # baseline –¥–ª—è gemma-12b –±–µ–∑ spec decoding
            speedup = tokens_per_sec / estimated_baseline
            
            print(f"\nüí° –û—Ü—ñ–Ω–æ—á–Ω–µ –ø—Ä–∏—Å–∫–æ—Ä–µ–Ω–Ω—è: ~{speedup:.1f}x")
            print(f"   (–ø–æ—Ä—ñ–≤–Ω—è–Ω–æ –∑ baseline ~{estimated_baseline} tokens/s)\n")
        
        return results
    
    def get_stats(self) -> Dict:
        """–û—Ç—Ä–∏–º–∞—Ç–∏ –∑–∞–≥–∞–ª—å–Ω—É —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Ä–æ–±–æ—Ç–∏"""
        if self.total_time == 0:
            return {"message": "–©–µ –Ω–µ –±—É–ª–æ –∑–≥–µ–Ω–µ—Ä–æ–≤–∞–Ω–æ –∂–æ–¥–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç—É"}
        
        return {
            "total_tokens_generated": self.total_tokens_generated,
            "total_time": self.total_time,
            "average_tokens_per_second": self.total_tokens_generated / self.total_time,
            "target_model": TARGET_MODEL,
            "draft_model": DRAFT_MODEL,
        }


# üìä –ü—Ä–∏–∫–ª–∞–¥ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è
if __name__ == "__main__":
    # –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è summarizer
    summarizer = GemmaSpeculativeSummarizer(llm, tokenizer)
    
    # –¢–µ—Å—Ç–æ–≤—ñ —Ç–µ–∫—Å—Ç–∏ (–±—ñ–ª—å—à –¥–æ–≤–≥—ñ –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü—ñ—ó –ø–µ—Ä–µ–≤–∞–≥ spec decoding)
    sample_texts = [
        """–ö–≤–∞–Ω—Ç–æ–≤—ñ –∫–æ–º–ø'—é—Ç–µ—Ä–∏ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—é—Ç—å –ø—Ä–∏–Ω—Ü–∏–ø–∏ –∫–≤–∞–Ω—Ç–æ–≤–æ—ó –º–µ—Ö–∞–Ω—ñ–∫–∏ –¥–ª—è –æ–±—Ä–æ–±–∫–∏ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—ó. 
        –ù–∞ –≤—ñ–¥–º—ñ–Ω—É –≤—ñ–¥ –∫–ª–∞—Å–∏—á–Ω–∏—Ö –∫–æ–º–ø'—é—Ç–µ—Ä—ñ–≤, —è–∫—ñ –ø—Ä–∞—Ü—é—é—Ç—å –∑ –±—ñ—Ç–∞–º–∏ (0 –∞–±–æ 1), –∫–≤–∞–Ω—Ç–æ–≤—ñ 
        –∫–æ–º–ø'—é—Ç–µ—Ä–∏ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—é—Ç—å –∫—É–±—ñ—Ç–∏, —è–∫—ñ –º–æ–∂—É—Ç—å –ø–µ—Ä–µ–±—É–≤–∞—Ç–∏ –≤ —Å—É–ø–µ—Ä–ø–æ–∑–∏—Ü—ñ—ó —Å—Ç–∞–Ω—ñ–≤. 
        –¶–µ –¥–æ–∑–≤–æ–ª—è—î —ó–º –≤–∏–∫–æ–Ω—É–≤–∞—Ç–∏ –ø–µ–≤–Ω—ñ –æ–±—á–∏—Å–ª–µ–Ω–Ω—è –µ–∫—Å–ø–æ–Ω–µ–Ω—Ü—ñ–π–Ω–æ —à–≤–∏–¥—à–µ –∑–∞ –∫–ª–∞—Å–∏—á–Ω—ñ —Å–∏—Å—Ç–µ–º–∏. 
        –ö–≤–∞–Ω—Ç–æ–≤—ñ –∫–æ–º–ø'—é—Ç–µ—Ä–∏ –º–∞—é—Ç—å –ø–æ—Ç–µ–Ω—Ü—ñ–∞–ª —Ä–µ–≤–æ–ª—é—Ü—ñ–æ–Ω—ñ–∑—É–≤–∞—Ç–∏ –∫—Ä–∏–ø—Ç–æ–≥—Ä–∞—Ñ—ñ—é, –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—é —Ç–∞ 
        —Å–∏–º—É–ª—è—Ü—ñ—é –º–æ–ª–µ–∫—É–ª—è—Ä–Ω–∏—Ö —Å–∏—Å—Ç–µ–º. –û–¥–Ω–∞–∫ –≤–æ–Ω–∏ –Ω–∞–¥–∑–≤–∏—á–∞–π–Ω–æ —á—É—Ç–ª–∏–≤—ñ –¥–æ —à—É–º—ñ–≤ —ñ –ø–æ—Ç—Ä–µ–±—É—é—Ç—å 
        –µ–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω–æ –Ω–∏–∑—å–∫–∏—Ö —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä –¥–ª—è —Ä–æ–±–æ—Ç–∏. –ü—Ä–æ–≤—ñ–¥–Ω—ñ –∫–æ–º–ø–∞–Ω—ñ—ó, —Ç–∞–∫—ñ —è–∫ IBM, Google —Ç–∞ 
        IonQ, –∞–∫—Ç–∏–≤–Ω–æ –ø—Ä–∞—Ü—é—é—Ç—å –Ω–∞–¥ —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è–º —Å—Ç–∞–±—ñ–ª—å–Ω–∏—Ö –∫–≤–∞–Ω—Ç–æ–≤–∏—Ö —Å–∏—Å—Ç–µ–º.""",
        
        """–ë–ª–æ–∫—á–µ–π–Ω ‚Äî —Ü–µ —Ä–æ–∑–ø–æ–¥—ñ–ª–µ–Ω–∞ –±–∞–∑–∞ –¥–∞–Ω–∏—Ö, —è–∫–∞ –∑–±–µ—Ä—ñ–≥–∞—î –∑–∞–ø–∏—Å–∏ –ø—Ä–æ —Ç—Ä–∞–Ω–∑–∞–∫—Ü—ñ—ó —É –≤–∏–≥–ª—è–¥—ñ 
        –ª–∞–Ω—Ü—é–∂–∫–∞ –±–ª–æ–∫—ñ–≤. –ö–æ–∂–µ–Ω –±–ª–æ–∫ –º—ñ—Å—Ç–∏—Ç—å –∫—Ä–∏–ø—Ç–æ–≥—Ä–∞—Ñ—ñ—á–Ω–∏–π —Ö–µ—à –ø–æ–ø–µ—Ä–µ–¥–Ω—å–æ–≥–æ –±–ª–æ–∫—É, —â–æ —Ä–æ–±–∏—Ç—å 
        —Å–∏—Å—Ç–µ–º—É –Ω–∞–¥–∑–≤–∏—á–∞–π–Ω–æ –∑–∞—Ö–∏—â–µ–Ω–æ—é –≤—ñ–¥ –ø—ñ–¥—Ä–æ–±–∫–∏. –¢–µ—Ö–Ω–æ–ª–æ–≥—ñ—è –±–ª–æ–∫—á–µ–π–Ω –ª–µ–∂–∏—Ç—å –≤ –æ—Å–Ω–æ–≤—ñ 
        –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç, –∞–ª–µ —ó—ó –∑–∞—Å—Ç–æ—Å—É–≤–∞–Ω–Ω—è –Ω–∞–±–∞–≥–∞—Ç–æ —à–∏—Ä—à–µ: –≤—ñ–¥ —Å–º–∞—Ä—Ç-–∫–æ–Ω—Ç—Ä–∞–∫—Ç—ñ–≤ –¥–æ —Å–∏—Å—Ç–µ–º 
        —É–ø—Ä–∞–≤–ª—ñ–Ω–Ω—è –ª–∞–Ω—Ü—é–≥–∞–º–∏ –ø–æ—Å—Ç–∞—á–∞–Ω–Ω—è. –ö–ª—é—á–æ–≤–∏–º–∏ –ø–µ—Ä–µ–≤–∞–≥–∞–º–∏ —î –¥–µ—Ü–µ–Ω—Ç—Ä–∞–ª—ñ–∑–∞—Ü—ñ—è, –ø—Ä–æ–∑–æ—Ä—ñ—Å—Ç—å 
        —Ç–∞ –Ω–µ–∑–º—ñ–Ω–Ω—ñ—Å—Ç—å –∑–∞–ø–∏—Å—ñ–≤. –û–¥–Ω–∞–∫ –±–ª–æ–∫—á–µ–π–Ω –º–∞—î –æ–±–º–µ–∂–µ–Ω–Ω—è —É —à–≤–∏–¥–∫–æ—Å—Ç—ñ –æ–±—Ä–æ–±–∫–∏ —Ç—Ä–∞–Ω–∑–∞–∫—Ü—ñ–π 
        —Ç–∞ —Å–ø–æ–∂–∏–≤–∞—î –∑–Ω–∞—á–Ω—É –∫—ñ–ª—å–∫—ñ—Å—Ç—å –µ–Ω–µ—Ä–≥—ñ—ó, –æ—Å–æ–±–ª–∏–≤–æ –≤ –º–µ—Ä–µ–∂–∞—Ö –∑ proof-of-work –∞–ª–≥–æ—Ä–∏—Ç–º–æ–º.""",
        
        """–ú–∞—à–∏–Ω–Ω–µ –Ω–∞–≤—á–∞–Ω–Ω—è ‚Äî —Ü–µ –ø—ñ–¥–≥–∞–ª—É–∑—å —à—Ç—É—á–Ω–æ–≥–æ —ñ–Ω—Ç–µ–ª–µ–∫—Ç—É, —è–∫–∞ –¥–æ–∑–≤–æ–ª—è—î —Å–∏—Å—Ç–µ–º–∞–º 
        –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ –ø–æ–∫—Ä–∞—â—É–≤–∞—Ç–∏ —Å–≤–æ—é –ø—Ä–æ–¥—É–∫—Ç–∏–≤–Ω—ñ—Å—Ç—å —á–µ—Ä–µ–∑ –¥–æ—Å–≤—ñ–¥. –ó–∞–º—ñ—Å—Ç—å —è–≤–Ω–æ–≥–æ –ø—Ä–æ–≥—Ä–∞–º—É–≤–∞–Ω–Ω—è 
        –ø—Ä–∞–≤–∏–ª, –∞–ª–≥–æ—Ä–∏—Ç–º–∏ –º–∞—à–∏–Ω–Ω–æ–≥–æ –Ω–∞–≤—á–∞–Ω–Ω—è –≤–∏—è–≤–ª—è—é—Ç—å –ø–∞—Ç–µ—Ä–Ω–∏ –≤ –¥–∞–Ω–∏—Ö. –Ü—Å–Ω—É—î —Ç—Ä–∏ –æ—Å–Ω–æ–≤–Ω—ñ 
        —Ç–∏–ø–∏: –Ω–∞–≤—á–∞–Ω–Ω—è –∑ —É—á–∏—Ç–µ–ª–µ–º, –¥–µ –º–æ–¥–µ–ª—å —Ç—Ä–µ–Ω—É—î—Ç—å—Å—è –Ω–∞ –º—ñ—á–µ–Ω–Ω–∏—Ö –¥–∞–Ω–∏—Ö; –Ω–∞–≤—á–∞–Ω–Ω—è –±–µ–∑ —É—á–∏—Ç–µ–ª—è, 
        –¥–µ –º–æ–¥–µ–ª—å –∑–Ω–∞—Ö–æ–¥–∏—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä–∏ –≤ –Ω–µ–º—ñ—á–µ–Ω–Ω–∏—Ö –¥–∞–Ω–∏—Ö; —Ç–∞ –Ω–∞–≤—á–∞–Ω–Ω—è –∑ –ø—ñ–¥–∫—Ä—ñ–ø–ª–µ–Ω–Ω—è–º, –¥–µ –∞–≥–µ–Ω—Ç 
        –≤—á–∏—Ç—å—Å—è —á–µ—Ä–µ–∑ –≤–∑–∞—î–º–æ–¥—ñ—é –∑ —Å–µ—Ä–µ–¥–æ–≤–∏—â–µ–º. –ì–ª–∏–±–æ–∫–µ –Ω–∞–≤—á–∞–Ω–Ω—è, —è–∫–µ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î –Ω–µ–π—Ä–æ–Ω–Ω—ñ –º–µ—Ä–µ–∂—ñ 
        –∑ –±–∞–≥–∞—Ç—å–º–∞ —à–∞—Ä–∞–º–∏, –¥–æ—Å—è–≥–ª–æ –≤—Ä–∞–∂–∞—é—á–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ —É —Ä–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—ñ –∑–æ–±—Ä–∞–∂–µ–Ω—å, –æ–±—Ä–æ–±—Ü—ñ 
        –ø—Ä–∏—Ä–æ–¥–Ω–æ—ó –º–æ–≤–∏ —Ç–∞ —ñ–Ω—à–∏—Ö —Å–∫–ª–∞–¥–Ω–∏—Ö –∑–∞–¥–∞—á–∞—Ö.""",
    ]
    
    print("="*80)
    print("üéØ –¢–ï–°–¢–£–í–ê–ù–ù–Ø SPECULATIVE DECODING")
    print("="*80)
    print(f"\nüì¶ Target Model: {TARGET_MODEL}")
    print(f"‚ö° Draft Model: {DRAFT_MODEL}")
    print(f"üî¢ –ö—ñ–ª—å–∫—ñ—Å—Ç—å speculative tokens: 5\n")
    
    # –¢–µ—Å—Ç balanced –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó
    print("="*80)
    print("üìä –¢–µ—Å—Ç: Balanced –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—è")
    print("="*80 + "\n")
    
    results = summarizer.summarize_batch(
        texts=sample_texts,
        config="balanced",
        show_progress=True,
        show_speedup=True,
    )
    
    # –í–∏–≤–µ–¥–µ–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
    for i, result in enumerate(results, 1):
        print(f"üìÑ –¢–µ–∫—Å—Ç #{i}:")
        print(f"–û—Ä–∏–≥—ñ–Ω–∞–ª: {result['original_text'][:100]}...")
        print(f"\n‚ú® –†–µ–∑—é–º–µ ({result['tokens_generated']} —Ç–æ–∫–µ–Ω—ñ–≤):")
        print(f"{result['summary']}")
        print(f"üèÅ Finish reason: {result['finish_reason']}")
        print("\n" + "-"*80 + "\n")
    
    # –ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ–π
    print("="*80)
    print("üî¨ –ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è —Ä—ñ–∑–Ω–∏—Ö –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ–π")
    print("="*80 + "\n")
    
    test_text = sample_texts[0]
    
    for config_name in ["precise", "balanced", "creative"]:
        print(f"--- {config_name.upper()} ---")
        result = summarizer.summarize_batch(
            texts=[test_text],
            config=config_name,
            show_progress=False,
            show_speedup=False,
        )[0]
        print(f"‚ú® {result['summary']}")
        print(f"üìä –¢–æ–∫–µ–Ω—ñ–≤: {result['tokens_generated']}\n")
    
    # –ó–∞–≥–∞–ª—å–Ω–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    print("="*80)
    print("üìà –ó–ê–ì–ê–õ–¨–ù–ê –°–¢–ê–¢–ò–°–¢–ò–ö–ê –†–û–ë–û–¢–ò")
    print("="*80 + "\n")
    
    stats = summarizer.get_stats()
    print(f"üî¢ –í—Å—å–æ–≥–æ —Ç–æ–∫–µ–Ω—ñ–≤ –∑–≥–µ–Ω–µ—Ä–æ–≤–∞–Ω–æ: {stats['total_tokens_generated']}")
    print(f"‚è±Ô∏è  –ó–∞–≥–∞–ª—å–Ω–∏–π —á–∞—Å: {stats['total_time']:.2f}s")
    print(f"‚ö° –°–µ—Ä–µ–¥–Ω—è —à–≤–∏–¥–∫—ñ—Å—Ç—å: {stats['average_tokens_per_second']:.1f} tokens/s")
    print(f"\nüéØ Target: {stats['target_model']}")
    print(f"‚ö° Draft: {stats['draft_model']}")
    
    print("\n" + "="*80)
    print("üí° TIPS –¥–ª—è –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—ó:")
    print("="*80)
    print("""
1. üìä num_speculative_tokens: 
   - 3-5 –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ –¥–ª—è –±—ñ–ª—å—à–æ—Å—Ç—ñ –∑–∞–¥–∞—á
   - –ë—ñ–ª—å—à–µ = –±—ñ–ª—å—à–µ overhead, –∞–ª–µ –ø–æ—Ç–µ–Ω—Ü—ñ–π–Ω–æ —à–≤–∏–¥—à–µ
   - –ú–µ–Ω—à–µ = –º–µ–Ω—à–µ overhead, –∞–ª–µ –º–µ–Ω—à–µ –ø—Ä–∏—Å–∫–æ—Ä–µ–Ω–Ω—è

2. üéØ –í–∏–±—ñ—Ä draft –º–æ–¥–µ–ª—ñ:
   - –ú–∞—î –±—É—Ç–∏ –∑ —Ç—ñ—î—ó –∂ —Ä–æ–¥–∏–Ω–∏ (Gemma 2)
   - –°–ø—ñ–≤–≤—ñ–¥–Ω–æ—à–µ–Ω–Ω—è 1:3 (4B draft, 12B target) - –æ–ø—Ç–∏–º–∞–ª—å–Ω–µ
   - Draft –º–æ–¥–µ–ª—å –º–∞—î –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏ —Ç–æ–π –∂–µ —Å–ª–æ–≤–Ω–∏–∫

3. ‚öôÔ∏è gpu_memory_utilization:
   - 0.85 –¥–ª—è –¥–≤–æ—Ö –º–æ–¥–µ–ª–µ–π (draft + target)
   - –Ø–∫—â–æ OOM - –∑–º–µ–Ω—à –¥–æ 0.75-0.8

4. üöÄ –î–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ—ó —à–≤–∏–¥–∫–æ—Å—Ç—ñ:
   - use_v2_block_manager=True
   - enable_chunked_prefill=True
   - –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π batch processing
    """)
